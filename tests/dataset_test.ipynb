{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "# Add the root project directory to the Python path\n",
    "ROOT = Path.cwd().parent  # This will get the project root since the notebook is in 'notebooks/'\n",
    "sys.path.append(str(ROOT))\n",
    "from configs.path_config import GROUP1A, EXTRACTED_DATA_DIR\n",
    "from src.processing import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrainDataset(Dataset):\n",
    "    def __init__(self, root, group, sequence_length, test_size=0.2):\n",
    "        self.sequences = []\n",
    "\n",
    "        # Load and process each file\n",
    "        for file in group:\n",
    "            path = EXTRACTED_DATA_DIR / 'group1' / file\n",
    "            df = pd.read_csv(path)\n",
    "            processed_df = preprocessing.preprocessing_pipeline(df)\n",
    "            strain_series = processed_df[\"Strain\"].fillna(0)\n",
    "\n",
    "            # Create rolling sequences\n",
    "            for i in range(len(strain_series) - sequence_length):\n",
    "                self.sequences.append(strain_series[i: i + sequence_length])\n",
    "\n",
    "        # Convert to tensor\n",
    "        self.sequences = torch.tensor(self.sequences, dtype=torch.float32)\n",
    "\n",
    "        # Split the sequences into training and testing\n",
    "        train_size = int(len(self.sequences) * (1 - test_size))\n",
    "        self.train_data, self.test_data = torch.split(self.sequences, [train_size, len(self.sequences) - train_size])\n",
    "\n",
    "        # Define DataLoaders\n",
    "        self.train_dataloader = DataLoader(self.train_data, batch_size=32, shuffle=True)\n",
    "        self.test_dataloader = DataLoader(self.test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_data)  # Return length of training data\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.train_data[idx]  # Return a training sequence\n",
    "\n",
    "    def get_test_data(self):\n",
    "        return self.test_data  # Return test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of using it outside the class\n",
    "sequence_length = 128\n",
    "dataset = StrainDataset(EXTRACTED_DATA_DIR, GROUP1A, sequence_length)\n",
    "\n",
    "# Access the data loaders directly from the class instance\n",
    "train_loader = dataset.train_dataloader\n",
    "test_loader = dataset.test_dataloader"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exjobb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
