{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80f8270e",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71076b4",
   "metadata": {},
   "source": [
    "#### Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1476aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# Add the root project directory to the Python path\n",
    "ROOT = Path.cwd().parent  # This will get the project root since the notebook is in 'notebooks/'\n",
    "sys.path.append(str(ROOT))\n",
    "from configs.path_config import EXTRACTED_DATA_DIR, MODEL_DIR, OUTPUT_DIR\n",
    "from configs.model_config import INPUT_FEATURES, OUTPUT_FEATURES, PARAMS\n",
    "from src.processing import dataset\n",
    "from src import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b56586",
   "metadata": {},
   "source": [
    "#### Create the data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4992b42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = EXTRACTED_DATA_DIR / 'group_alvbrodel_shifted'\n",
    "data = dataset.StrainDataset(\n",
    "    folder_path, \n",
    "    INPUT_FEATURES, \n",
    "    OUTPUT_FEATURES, \n",
    "    sequence_length=PARAMS['sequence_length'], \n",
    "    batch_size=PARAMS['batch_size'],  \n",
    "    test_size=PARAMS['test_size'], \n",
    "    start_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e153dbdb",
   "metadata": {},
   "source": [
    "#### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e58de63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'lstm_model_supportII_20_128_2_0.001_0.3'\n",
    "model_path = MODEL_DIR / model_name\n",
    "model, mean_error, std_error = utils.load_model_and_threshold(model_path)\n",
    "threshold = mean_error + 10 * std_error\n",
    "print(f\"Mean error: {mean_error}\")\n",
    "print(f\"Standard deviation of error: {std_error}\")\n",
    "print(f\"Threshold: {threshold}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a929a62",
   "metadata": {},
   "source": [
    "#### Plot the anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02881a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(data.test_data)\n",
    "\n",
    "input_feature_names = data.input_feature_names\n",
    "output_feature_names = data.output_feature_names\n",
    "print(f\"Feature names: {output_feature_names}\")\n",
    "print(f\"Timestamps test length: {len(data.timestamps_test)}\")\n",
    "print(f\"Sample timestamps: {data.timestamps_test[:5]}\")\n",
    "timestamps = pd.DatetimeIndex(data.timestamps_test[:N])\n",
    "\n",
    "# save_dir = OUTPUT_DIR / 'figures' / 'RESULTS' / f\"{model_name}_reconstruction_plot_sep.pdf\"\n",
    "save_dir = OUTPUT_DIR / 'figures' / 'RESULTS' / f\"{model_name}_reconstruction_plot.pdf\"\n",
    "reconstructed = utils.plot_reconstruction(data.test_data, model, N, input_feature_names, output_feature_names, timestamps, threshold, save_dir, mode=3, subplots=False) #put subplots=False to plot all features in separate plots\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exjobb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
