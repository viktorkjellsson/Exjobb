{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import math\n",
    "from pathlib import Path\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# Add the root project directory to the Python path\n",
    "project_root = Path.cwd().parent  # This will get the project root since the notebook is in 'notebooks/'\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "from configs.path_config import EXTRACTED_DATA_DIR, OUTPUT_DIR\n",
    "print(EXTRACTED_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directory (could be 'EXTRACTED_DATA_DIR' or your project root directory)\n",
    "base_dir = Path(EXTRACTED_DATA_DIR)\n",
    "\n",
    "# Path to the folder containing CSV files\n",
    "folder = base_dir / 'group_alvbrodel_shifted'\n",
    "\n",
    "# Get the list of files using pathlib\n",
    "files = [file for file in folder.iterdir() if file.is_file() and file.suffix == '.csv']\n",
    "\n",
    "dfs = {}\n",
    "\n",
    "for file in files:\n",
    "    try:\n",
    "        # Extract the file name without the extension using pathlib's `stem` (no need for rsplit)\n",
    "        name = file.stem  # This gives the name without the extension\n",
    "        dfs[name] = pd.read_csv(file, parse_dates=['Time'])\n",
    "        print(f\"Loaded: {file.name} as dfs[{name}]\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"The file was not found: {file}\")\n",
    "\n",
    "print(f'\\n\\nFound {len(files)} files in the folder {folder}.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.processing import preprocessing\n",
    "\n",
    "interpolate_threshold = 0\n",
    "for name in dfs:\n",
    "    print(f'----{name}')\n",
    "    dfs[name] = preprocessing.preprocessing_pipeline(dfs[name], interpolate_threshold=interpolate_threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def generate_random_timestamps(n):\n",
    "    start = datetime.strptime(\"20090605000000\", \"%Y%m%d%H%M%S\")\n",
    "    end = datetime.strptime(\"20210611160000\", \"%Y%m%d%H%M%S\")\n",
    "    \n",
    "    # Generate all possible timestamps at four-hour intervals\n",
    "    timestamps = []\n",
    "    current = start\n",
    "    while current <= end:\n",
    "        timestamps.append(current.strftime(\"%Y%m%d%H0000\"))\n",
    "        current += timedelta(hours=4)\n",
    "    \n",
    "    # Sample n random timestamps\n",
    "    return random.sample(timestamps, n)\n",
    "\n",
    "# Example usage:\n",
    "n = 10  # Change this to the number of timestamps you need\n",
    "random_timestamps = generate_random_timestamps(n)\n",
    "print(random_timestamps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, df in dfs.items():\n",
    "    print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dfs = len(dfs)\n",
    "cols = 3  \n",
    "rows = math.ceil(num_dfs / cols) \n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(15, 5 * rows))  \n",
    "axes = axes.flatten()  # Flatten in case of a single row\n",
    "\n",
    "for i, (name, df) in enumerate(dfs.items()):\n",
    "    sns.histplot(df['Strain'], bins=30, kde=True, ax=axes[i])  \n",
    "    axes[i].set_title(f'Distribution of Strain\\n{name}')\n",
    "    axes[i].set_xlabel('Strain')\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "\n",
    "# Hide any unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])  # Remove extra subplots\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dfs = len(dfs)\n",
    "cols = 3 \n",
    "rows = math.ceil(num_dfs / cols) \n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(15, 5 * rows))\n",
    "axes = axes.flatten()  # Flatten in case of a single row\n",
    "\n",
    "for i, (name, df) in enumerate(dfs.items()):\n",
    "    sns.boxplot(y=df['Strain'], ax=axes[i])  \n",
    "    axes[i].set_title(f'Boxplot of Strain\\n{name}')\n",
    "    axes[i].set_ylabel('Strain')\n",
    "\n",
    "# Hide any unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])  # Remove extra subplots\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_regions(df, threshold_valid):\n",
    "    valid_indices = df[df['Strain'].notna()].index.tolist()\n",
    "    consecutive_valid_regions = []\n",
    "    start_idx = None\n",
    "\n",
    "    for i in range(len(valid_indices)):\n",
    "        if start_idx is None:\n",
    "            start_idx = valid_indices[i]\n",
    "        if i == len(valid_indices) - 1 or valid_indices[i] + 1 != valid_indices[i + 1]:\n",
    "            end_idx = valid_indices[i]\n",
    "            if (end_idx - start_idx + 1) >= threshold_valid:  # Threshold for region length\n",
    "                consecutive_valid_regions.append((start_idx, end_idx))\n",
    "            start_idx = None\n",
    "\n",
    "    valid_regions_sorted = [\n",
    "            (start, end, df.loc[start, 'Time'], df.loc[end, 'Time'], end - start + 1)\n",
    "            for start, end in consecutive_valid_regions\n",
    "        ]\n",
    "    \n",
    "    valid_regions_sorted.sort(key=lambda x: x[4], reverse=True)\n",
    "\n",
    "    return consecutive_valid_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.cm import get_cmap\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "tab10_color = mcolors.to_hex(get_cmap('tab10')(0))  # Pick the first tab10 color\n",
    "\n",
    "# Compute valid regions for each dataset\n",
    "for name, df in dfs.items():\n",
    "    df = df[df['Time']<= '2015-06-11 16:00:00']  # Filter the DataFrame to only include data up to the specified date\n",
    "    df = df[df['Time']>= '2009-10-16 16:00:00']  # Filter the DataFrame to only include data up to the specified date\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.update_layout(width=1600, height=400)  # Set figure size\n",
    "    \n",
    "    # Add traces for both raw strain data and rolling mean\n",
    "    fig.add_trace(go.Scatter(x=df['Time'], y=df['Strain'], mode='lines', name='Raw Strain Data', line=dict(color=tab10_color)))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f'{name}',\n",
    "        xaxis_title='Time',\n",
    "        yaxis_title='Strain',\n",
    "        xaxis_title_font=dict(size=20),\n",
    "        yaxis_title_font=dict(size=20),\n",
    "        xaxis_rangeslider_visible=False,\n",
    "        xaxis=dict(\n",
    "            tickformat='%b %Y',          # Format as MM-DD\n",
    "            tickfont=dict(size=14),\n",
    "            dtick=\"M1\",                  # Tick every month\n",
    "            tickangle=45\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            tickfont=dict(size=14)\n",
    "        )\n",
    ")\n",
    "\n",
    "\n",
    "    # Show figure\n",
    "    fig.show()\n",
    "    #save figure as pdf\n",
    "    save_path = OUTPUT_DIR / f'{name}_time_dependencies.pdf'\n",
    "    fig.write_image(save_path, format='pdf')\n",
    "    print(f\"Figure saved as {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_valid = 100  # Apply threshold after finding overlapping regions\n",
    "consecutive_regions_dict = {}  # Store consecutive valid regions for each dataset\n",
    "\n",
    "# Define window size for the rolling mean (adjust this depending on your data)\n",
    "rolling_window_daily = 6 \n",
    "rolling_window_weekly = 42\n",
    "\n",
    "# Compute valid regions for each dataset\n",
    "for name, df in dfs.items():\n",
    "    consecutive_valid_regions = valid_regions(df, threshold_valid)\n",
    "    consecutive_regions_dict[name] = consecutive_valid_regions\n",
    "\n",
    "    # Compute rolling mean for the 'Strain' data\n",
    "    df['strain_rolling_mean_daily'] = df['Strain'].rolling(window=rolling_window_daily, min_periods=1).mean()\n",
    "    df['strain_rolling_mean_weekly'] = df['Strain'].rolling(window=rolling_window_weekly, min_periods=1).mean()\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.update_layout(width=1600, height=400)  # Set figure size\n",
    "    \n",
    "    # Add traces for both raw strain data and rolling mean\n",
    "    fig.add_trace(go.Scatter(x=df['Time'], y=df['Strain'], mode='lines', name='Raw Strain Data'))\n",
    "    fig.add_trace(go.Scatter(x=df['Time'], y=df['strain_rolling_mean_daily'], mode='lines', name='Rolling Mean (daily)', line=dict(dash='dashdot')))\n",
    "    fig.add_trace(go.Scatter(x=df['Time'], y=df['strain_rolling_mean_weekly'], mode='lines', name='Rolling Mean (monthly)', line=dict(dash='dashdot')))\n",
    "    \n",
    "    # Shade regions with NaNs\n",
    "    for start, end in consecutive_valid_regions:\n",
    "        fig.add_vrect(x0=df['Time'].loc[start], x1=df['Time'].loc[end], fillcolor='green', opacity=0.3, line_width=0)\n",
    "\n",
    "    # Labels and title\n",
    "    fig.update_layout(\n",
    "        title=f'Consecutive regions of more than {threshold_valid} valid values (imputed up to {interpolate_threshold} steps) <br> {name}',\n",
    "        xaxis_title='Time',\n",
    "        yaxis_title='Strain',\n",
    "        xaxis_rangeslider_visible=True  # Optional: adds a range slider at the bottom\n",
    "    )   \n",
    "\n",
    "    # Show figure\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def find_overlapping_regions(*series_regions):\n",
    "    \"\"\"\n",
    "    Find overlapping regions where all time series overlap.\n",
    "    \n",
    "    Args:\n",
    "        *series_regions: Variable number of lists with (start, end) tuples for each time series.\n",
    "        \n",
    "    Returns:\n",
    "        overlapping_regions: List of (start, end) tuples where all series overlap.\n",
    "    \"\"\"\n",
    "    if not series_regions:\n",
    "        return []\n",
    "\n",
    "    overlapping_regions = series_regions[0]  # Start with the first series' valid regions\n",
    "\n",
    "    for regions in series_regions[1:]:\n",
    "        new_overlapping = []\n",
    "        for s1, e1 in overlapping_regions:\n",
    "            for s2, e2 in regions:\n",
    "                # Compute overlap between two regions\n",
    "                start_overlap = max(s1, s2)\n",
    "                end_overlap = min(e1, e2)\n",
    "\n",
    "                # If a valid overlap exists, store it\n",
    "                if start_overlap <= end_overlap:\n",
    "                    new_overlapping.append((start_overlap, end_overlap))\n",
    "\n",
    "        overlapping_regions = new_overlapping  # Update overlapping regions\n",
    "\n",
    "        if not overlapping_regions:  # Stop if no overlapping region remains\n",
    "            break\n",
    "\n",
    "    return overlapping_regions\n",
    "\n",
    "# Compute overlapping regions across all datasets\n",
    "overlapping_regions = find_overlapping_regions(*consecutive_regions_dict.values())\n",
    "print(overlapping_regions)\n",
    "\n",
    "# **Apply threshold on overlapping regions**\n",
    "filtered_overlapping_regions = [\n",
    "    (start, end) for start, end in overlapping_regions if (end - start) >= threshold_valid\n",
    "]\n",
    "\n",
    "filtered_overlapping_regions = np.array(filtered_overlapping_regions)  # Convert list to NumPy array\n",
    "if overlapping_regions != []:\n",
    "    filtered_overlapping_regions_length = filtered_overlapping_regions[:, 1] - filtered_overlapping_regions[:, 0]\n",
    "    print(f'Found {len(filtered_overlapping_regions_length)} overlapping regions with the lengths >{threshold_valid}: {filtered_overlapping_regions_length}')\n",
    "else: \n",
    "    print('No overlapping regions found')\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure()\n",
    "fig.update_layout(\n",
    "    width=1600,\n",
    "    height=600,\n",
    "    legend=dict(\n",
    "        orientation=\"h\",  # Horizontal orientation\n",
    "        yanchor=\"top\",  # Anchor the legend to the top of its container\n",
    "        y=-0.2,  # Move the legend below the plot\n",
    "        xanchor=\"center\",  \n",
    "        x=0.5  # Center the legend horizontally\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add each time series to the figure\n",
    "for name, df in dfs.items():\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df['Time'], \n",
    "        y=df['Strain'], \n",
    "        mode='lines', \n",
    "        name=name  # Dynamic name\n",
    "    ))\n",
    "\n",
    "\n",
    "first_key = next(iter(dfs))  # Get the first key from the dictionary\n",
    "first_df = dfs[first_key]  # Retrieve the corresponding DataFrame\n",
    "\n",
    "# Highlight the filtered overlapping regions using the first dataset's time reference\n",
    "for start, end in filtered_overlapping_regions:\n",
    "    fig.add_vrect(\n",
    "        x0=first_df['Time'].loc[start],  # Use first df for time axis reference\n",
    "        x1=first_df['Time'].loc[end], \n",
    "        fillcolor='green', \n",
    "        opacity=0.3, \n",
    "        line_width=0\n",
    "    )\n",
    "# Show figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "import plotly.graph_objects as go\n",
    "from pathlib import Path\n",
    "\n",
    "# Merge DataFrames\n",
    "merged_df = pd.concat([df.set_index(\"Time\")[\"Strain\"].rename(name) for name, df in dfs.items()], axis=1)\n",
    "corr_matrix = merged_df.corr()\n",
    "corr_matrix_formatted = corr_matrix.applymap(lambda x: f'{x:.2f}')\n",
    "\n",
    "tab10 = cm.get_cmap('tab10')\n",
    "\n",
    "# Choose two specific tab10 colors\n",
    "color_start = mcolors.to_hex(tab10(3))  # Blue\n",
    "color_end = mcolors.to_hex(tab10(0))    # Orange\n",
    "\n",
    "# Create a custom continuous scale with just those two\n",
    "custom_scale = [\n",
    "    [0.0, color_start],\n",
    "    [0.5, 'white'],\n",
    "    [1.0, color_end]\n",
    "]\n",
    "\n",
    "# Create annotations for each cell\n",
    "annotations = []\n",
    "for i in range(corr_matrix.shape[0]):\n",
    "    for j in range(corr_matrix.shape[1]):\n",
    "        annotations.append(\n",
    "            dict(\n",
    "                x=corr_matrix.columns[j],\n",
    "                y=corr_matrix.index[i],\n",
    "                text=corr_matrix_formatted.iat[i, j],\n",
    "                showarrow=False,\n",
    "                font=dict(color=\"black\")\n",
    "            )\n",
    "        )\n",
    "\n",
    "# Create heatmap\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "    z=corr_matrix.values,\n",
    "    x=corr_matrix.columns,\n",
    "    y=corr_matrix.index,\n",
    "    colorscale=custom_scale,\n",
    "    zmin=-1,\n",
    "    zmax=1,\n",
    "    colorbar=dict(title=\"Correlation Index\",\n",
    "                   tickvals=[-1, -0.5, 0, 0.5, 1],\n",
    "                   ticktext=[\"-1\", \"-0.5\", \"0\", \"0.5\", \"1\"],\n",
    "                   title_font=dict(size=18),\n",
    "                   tickfont=dict(size=16),\n",
    "                   xanchor=\"left\",\n",
    "                   titleside=\"right\"\n",
    "                  ),\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Strain Correlation for All Points\",\n",
    "    title_font=dict(size=20),\n",
    "    annotations=annotations,\n",
    "    width=1000,\n",
    "    height=1000,\n",
    "    title_x=0.5,\n",
    "    xaxis=dict(\n",
    "        title=\"\",\n",
    "        tickfont=dict(size=12),\n",
    "        tickangle=45,\n",
    "        ticks=\"outside\",\n",
    "        showgrid=False\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=\"\",\n",
    "        tickfont=dict(size=12),\n",
    "        ticks=\"outside\",\n",
    "        showgrid=False\n",
    "    ),\n",
    "    \n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Save\n",
    "save_path = Path(OUTPUT_DIR / 'figures' / 'correlation_heatmaps' / 'correlation_heatmap_all.pdf')\n",
    "fig.write_image(save_path, width=1000, height=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Example: Assume 'dfs' is a dictionary with beam names as keys and DataFrames as values\n",
    "# Each DataFrame has 'timestamp' and 'strain' columns\n",
    "\n",
    "# Merge DataFrames on 'timestamp' to align them\n",
    "merged_df = pd.concat([df.set_index(\"Time\")[\"Strain\"].rename(name) for name, df in dfs.items()], axis=1)\n",
    "\n",
    "# Compute the correlation matrix with missing values (using pairwise deletion)\n",
    "corr_matrix = merged_df.corr()\n",
    "\n",
    "# Format the correlation matrix to two decimal places\n",
    "corr_matrix_formatted = corr_matrix.applymap(lambda x: f'{x:.2f}')\n",
    "\n",
    "# Create a Plotly heatmap and include the formatted numbers in each cell\n",
    "fig = px.imshow(corr_matrix_formatted.astype(float),  # Convert formatted strings back to float for heatmap\n",
    "                color_continuous_scale='RdBu',\n",
    "                labels={'x': 'Loop', 'y': 'Loop', 'color': 'Correlation'},\n",
    "                title=\"Strain Correlation Between Strain Time Series (support V)\",\n",
    "                text_auto=True,  # Add correlation values in each cell\n",
    "                zmin=-1,  # Fix the minimum value of the color scale to -1\n",
    "                zmax=1   # Fix the maximum value of the color scale to 1\n",
    ")\n",
    "# Adjust the layout of the figure\n",
    "fig.update_layout(width=1000, height=1000, title_x=0.5)  # Adjust the width and height of the plot\n",
    "\n",
    "# Show the figure\n",
    "fig.show()\n",
    "\n",
    "save_path = Path(OUTPUT_DIR / 'figures' / 'correlation_heatmaps' / 'correlation_heatmap_support_V.pdf')\n",
    "fig.write_image(save_path, width=1000, height=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Availability of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import matplotlib.dates as mdates\n",
    "\n",
    "# def heatmap(loops_to_keep):\n",
    "#     # Read and process data\n",
    "#     df = pd.read_csv('txt/filelist.txt', delimiter=',', header=None)\n",
    "#     df.rename(columns={df.columns[0]: 'Date_path'}, inplace=True)\n",
    "#     df['Datetime'] = pd.to_datetime(df['Date_path'], format='%Y%m%d%H%M%S')\n",
    "#     df.rename(columns={df.columns[1]: 'Loop'}, inplace=True)\n",
    "#     dates = df['Datetime'].unique()\n",
    "\n",
    "#     loop_counts = df['Loop'].value_counts()\n",
    "#     print(f'Number of channels: {len(loop_counts)}')\n",
    "\n",
    "#     if loops_to_keep == 'all':\n",
    "#         # Keep all rows if 'all' is selected\n",
    "#         pass\n",
    "#     elif isinstance(loops_to_keep, str) and loops_to_keep.endswith('.txt'):\n",
    "#         # If it's a file path, read the loop names from the file\n",
    "#         with open(loops_to_keep, 'r') as f:\n",
    "#             loops_to_keep = [line.strip() for line in f.readlines()]  # Read and clean loop names\n",
    "#         # Filter the DataFrame to only keep the rows with the loops in the 'loops_to_keep' list\n",
    "#         df = df[df['Loop'].isin(loops_to_keep)]\n",
    "#     else:\n",
    "#         # If it's a list of loop names, use that list\n",
    "#         df = df[df['Loop'].isin(loops_to_keep)]\n",
    "\n",
    "#     # Create a boolean matrix using pivot_table()\n",
    "#     boolean_matrix = df.pivot_table(index='Loop', columns='Datetime', aggfunc=lambda x: 1, fill_value=0)\n",
    "#     boolean_matrix.columns = boolean_matrix.columns.droplevel(0)  # Drop the 'Date_path' level\n",
    "\n",
    "#     # Plot heatmap with horizontal lines only\n",
    "#     plt.figure(figsize=(160, 0.3*len(loops_to_keep)))\n",
    "#     ax = sns.heatmap(boolean_matrix, cmap=\"Blues\", cbar=False)\n",
    "\n",
    "#     plt.title(\"Availability of Data Over Time\")\n",
    "\n",
    "#     # Ensure labels are not rotated\n",
    "#     step = int(len(dates) / (len(dates)/30.5/6))\n",
    "#     ax.set_xticks(range(235, len(dates), step))  # Set ticks at intervals (235 is when September begins so that the ticks are at the beginning of each month)\n",
    "#     ax.set_xticklabels([dates[i].strftime('%Y-%m') for i in range(235, len(dates), step)], rotation=90, fontsize=30)\n",
    "\n",
    "#     ax.hlines(y=[i + 1 for i in range(len(boolean_matrix))], xmin=0, xmax=len(boolean_matrix.columns), color='black', linewidth=0.5)\n",
    "\n",
    "#     ax.set_yticklabels(boolean_matrix.index, rotation=0)\n",
    "\n",
    "#     # Show plot\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# # Define the option to read loops from a text file or specify 'all'\n",
    "# # loops_to_keep = 'N-B_Far_Comp.txt'  # Option: 'all' or path to a text file (e.g., 'loops.txt')\n",
    "# loops_to_keep = 'txt/comp_loops_notEI_filtered.txt'  # Option: 'all' or path to a text file (e.g., 'loops.txt')\n",
    "# title = 'Heatmap'\n",
    "# heatmap(loops_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import matplotlib.dates as mdates\n",
    "\n",
    "# def heatmap(loops_to_keep):\n",
    "\n",
    "#     # Ensure loops_to_keep is a list, even if it's a single string\n",
    "#     if isinstance(loops_to_keep, str):\n",
    "#         loops_to_keep = [loops_to_keep]\n",
    "\n",
    "#     # Read and process data\n",
    "#     df = pd.read_csv('txt/filelist.txt', delimiter=',', header=None)\n",
    "#     df.rename(columns={df.columns[0]: 'Date_path'}, inplace=True)\n",
    "#     df['Datetime'] = pd.to_datetime(df['Date_path'], format='%Y%m%d%H%M%S')\n",
    "#     df.rename(columns={df.columns[1]: 'Loop'}, inplace=True)\n",
    "#     dates = df['Datetime'].unique()\n",
    "\n",
    "#     loop_counts = df['Loop'].value_counts()\n",
    "#     print(f'Number of channels: {len(loop_counts)}')\n",
    "\n",
    "#     print(type(loops_to_keep))\n",
    "\n",
    "#     df = df[df['Loop'].isin(loops_to_keep)]\n",
    "\n",
    "#     # Create a boolean matrix using pivot_table()\n",
    "#     boolean_matrix = df.pivot_table(index='Loop', columns='Datetime', aggfunc=lambda x: 1, fill_value=0)\n",
    "#     boolean_matrix.columns = boolean_matrix.columns.droplevel(0)  # Drop the 'Date_path' level\n",
    "\n",
    "#     # Plot heatmap with horizontal lines only\n",
    "#     plt.figure(figsize=(160, 0.3*len(loops_to_keep)))\n",
    "#     ax = sns.heatmap(boolean_matrix, cmap=\"Blues\", cbar=False)\n",
    "\n",
    "#     plt.title(\"Availability of Data Over Time\")\n",
    "\n",
    "#     # Ensure labels are not rotated\n",
    "#     step = int(len(dates) / (len(dates)/30.5/6))\n",
    "#     ax.set_xticks(range(235, len(dates), step))  # Set ticks at intervals (235 is when September begins so that the ticks are at the beginning of each month)\n",
    "#     ax.set_xticklabels([dates[i].strftime('%Y-%m') for i in range(235, len(dates), step)], rotation=90, fontsize=30)\n",
    "\n",
    "#     ax.hlines(y=[i + 1 for i in range(len(boolean_matrix))], xmin=0, xmax=len(boolean_matrix.columns), color='black', linewidth=0.5)\n",
    "\n",
    "#     ax.set_yticklabels(boolean_matrix.index, rotation=0)\n",
    "\n",
    "#     # Show plot\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# # Define the option to read loops from a text file or specify 'all'\n",
    "# # Read the loop names from the .txt file before calling the function\n",
    "# # with open('txt/comp_loops_notEI_filtered1.txt', 'r') as f:\n",
    "# #     loops_to_keep = [line.strip() for line in f.readlines()]\n",
    "# loops_to_keep = ['N-B_Far_Comp.txt', 'N-Klaff_Comp.txt']  # Option: 'all' or path to a text file (e.g., 'loops.txt')\n",
    "# print(f'Loops to keep: {loops_to_keep}')\n",
    "# heatmap(loops_to_keep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exjobb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
